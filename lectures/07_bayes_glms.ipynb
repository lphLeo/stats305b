{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Idg01TtQ0LUR"
   },
   "source": [
    "# Bayesian GLMs\n",
    "\n",
    "We've taken our first steps toward becoming Bayesian statisticians! We learned about conjugate priors, which permit exact inference for simple probabilistic models like the beta-Bernoulli model. However, we found that more complex models require some form of approximate posterior inference. MCMC methods offer a general-purpose solution to approximate inference, allowing us to construct Markov chains for which the stationary distribution is the posterior distribution of interest. Now, let's put those ideas into practice by developing MCMC algorithms for Bayesian GLMs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7Zd_k_V3Caq"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzYjbiBZ6kMR"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install jaxtyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qpBB4DJbiFM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from fastprogress import progress_bar\n",
    "\n",
    "from jaxtyping import Array, Float\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from typing import Callable, Tuple\n",
    "from torch.distributions import Bernoulli, Gamma, MultivariateNormal, Normal, StudentT, \\\n",
    "    Uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z00GJ0wGII-5"
   },
   "source": [
    "## Bayesian Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIl4ZQW01F2H"
   },
   "source": [
    "### Model\n",
    "\n",
    "Let $y_i \\in \\{0,1\\}$ denote a binary observation and $x_i \\in \\mathbb{R}^p$ a corresponding vector of covariates. Let $\\beta \\in \\mathbb{R}^p$ denote the weights of our GLM. Our probabilistic model is,\n",
    "\\begin{align*}\n",
    "p(y, \\beta \\mid X)\n",
    "&= p(\\beta) \\prod_{i=1}^n p(y_i \\mid \\beta, x_i) \\\\\n",
    "&= \\mathrm{N}(\\beta \\mid 0, \\gamma^{-1} I) \\prod_{i=1}^n \\mathrm{Bern}(y_i \\mid f(x_i^\\top \\beta))\n",
    "\\end{align*}\n",
    "where $f: \\mathbb{R} \\mapsto (0,1)$ is the mean function. The canonical mean function is $f(a) = \\sigma(a) = 1 / (1+e^{-a})$, the logistic function, but we will consider other link functions in this lecture as well.\n",
    "\n",
    "**Our goal** is to approximate the posterior distribution $p(\\beta \\mid y, X)$. Unfortuantely, the posterior doesn't have a simple closed form since the Bernoulli likelihood is not conjugate with the Gaussian prior. Instead, we will develop MCMC algorithms to draw samples from the posterior distribution, at least asymptotically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OF_KpdPw3PFm"
   },
   "source": [
    "### Generate Synthetic Data\n",
    "\n",
    "Let's start by generating some synthetic data from a Bernoulli GLM with true weights $\\beta^\\star$. To make it easy to visualize, we'll use two dimensional features, so our weights will be three dimensional when we include an intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PhVbIynI3lIe"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(305 + ord('b'))\n",
    "\n",
    "# Set constants\n",
    "num_features = 3                # first \"feature\" is all ones\n",
    "num_data = 100                  # number of data points to sample\n",
    "mean_func = torch.sigmoid       # canonical mean function\n",
    "prior_scale = 3.                # std of Gaussian prior \\gamma^{-1/2}\n",
    "\n",
    "# Fix true weights. Sample features, and responses.\n",
    "true_weights = 1.5 * torch.tensor([0., 1., 1.])\n",
    "\n",
    "features = torch.column_stack([\n",
    "    torch.ones(num_data),\n",
    "    Normal(0, 1).sample((num_data, num_features-1))\n",
    "])\n",
    "responses = Bernoulli(mean_func(features @ true_weights)).sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "IZXXAp_E6GtN",
    "outputId": "5ef6d0f6-8493-424a-888a-e05553bfa6df"
   },
   "outputs": [],
   "source": [
    "def plot_sample(responses: Float[Array, \"num_data\"],\n",
    "                features: Float[Array, \"num_data num_features\"],\n",
    "                weights: Float[Array, \"num_features\"],\n",
    "                mean_func: Callable,\n",
    "                lim=(-3, 3),\n",
    "                num_points=100,\n",
    "                figsize=(5, 5)\n",
    "                ) -> None:\n",
    "    \"\"\" Helper function to plot the samples and weights of a Bernoulli GLM.\n",
    "    \"\"\"\n",
    "    x1, x2 = torch.meshgrid(torch.linspace(*lim, num_points),\n",
    "                            torch.linspace(*lim, num_points))\n",
    "    X = torch.column_stack([\n",
    "        torch.ones(num_points**2),\n",
    "        x1.ravel(),\n",
    "        x2.ravel()\n",
    "        ])\n",
    "    probs = mean_func(X @ weights)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    im = plt.imshow(probs.reshape((num_points, num_points)),\n",
    "                    cmap=\"Greys\", vmin=-0, vmax=1,\n",
    "                    alpha=0.8,\n",
    "                    extent=lim + tuple(reversed(lim)))\n",
    "    plt.plot(features[responses==1, 1], features[responses==1, 2],\n",
    "             'o', markersize=6, label=\"$y=1$\")\n",
    "    plt.plot(features[responses==0, 1], features[responses==0, 2],\n",
    "             'x', markersize=6, label=\"$y=0$\")\n",
    "\n",
    "    # Draw the true decision boundary\n",
    "    x1s = torch.linspace(*lim, 100)\n",
    "    x2s = -(weights[0] + weights[1] * x1s) / weights[2]\n",
    "    plt.plot(x1s, x2s, ':k')\n",
    "\n",
    "    # Clean up the axes\n",
    "    plt.xlabel(r\"$x_1$\")\n",
    "    plt.ylabel(r\"$x_2$\")\n",
    "    plt.xlim(lim)\n",
    "    plt.ylim(lim)\n",
    "    plt.legend()\n",
    "\n",
    "    # Colorbar\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.new_horizontal(size=\"5%\", pad=0.1)\n",
    "    fig.add_axes(cax)\n",
    "    plt.colorbar(im, cax=cax, label=\"probability\")\n",
    "\n",
    "plot_sample(responses, features, true_weights, mean_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37d197TD_lfe"
   },
   "source": [
    "### Log Probability\n",
    "\n",
    "Write a function to compute the log joint probability, $p(y, \\beta \\mid X)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Um9D57Og_qHG"
   },
   "outputs": [],
   "source": [
    "def log_joint(responses: Float[Array, \"num_data\"],\n",
    "              features: Float[Array, \"num_data num_features\"],\n",
    "              weights: Float[Array, \"num_features\"],\n",
    "              mean_func: Callable,\n",
    "              prior_scale: float) -> float:\n",
    "    \"\"\" Compute the log joint probability of the responses and\n",
    "    weights given the features. Assume the weights have a Gaussian\n",
    "    prior with mean zero and the specified scale.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Log joint probability of the responses and weights.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    lp = ...\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K98_gf8v7iX0"
   },
   "source": [
    "### Metropolis-Hastings\n",
    "\n",
    "First, let's implement a simple Metropolis-Hasting (MH) algorithm with a symmetric Gaussian proposal distribution,\n",
    "\\begin{align*}\n",
    "q(\\beta' \\mid \\beta) &= \\mathrm{N}(\\beta' \\mid \\beta, \\nu^2 I)\n",
    "\\end{align*}\n",
    "where $\\nu$ is the standard deviation of the proposal. This is called **random walk Metropolis-Hastings (RWMH)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyY63lSQFGje"
   },
   "source": [
    "#### Implement a single RWMH step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uq2i4f5tAhiL"
   },
   "outputs": [],
   "source": [
    "def rwmh_step(log_prob: Callable,\n",
    "              curr_weights: Float[Array, \"num_features\"],\n",
    "              curr_log_prob: float,\n",
    "              proposal_scale: float) -> \\\n",
    "              Tuple[Float[Array, \"num_features\"], float]:\n",
    "    \"\"\" Perform one step of random walk Metropolis-Hastings starting\n",
    "    from the current weights and using a symmetric Gaussian proposal\n",
    "    with the specified scale.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    log_prob: a function that takes in weights and outputs an unnormalized\n",
    "        log density. In our case, this function will return the log joint\n",
    "        probability of the weights and responses. As a function of the weights,\n",
    "        this is equal to the log posterior probability up to an unknown\n",
    "        normalizing constant.\n",
    "    curr_weights: the current parameters\n",
    "    curr_log_prob: the current log probability (so we don't have to re-evaluate)\n",
    "    proposal_scale: the standard deviation of the spherical Gaussian proposal\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Next sample of the weights and the corresponding log prob\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    new_weights = ...\n",
    "    new_lp = ...\n",
    "    return new_weights, new_lp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGYUc8p6FRcd"
   },
   "source": [
    "#### Implement the MCMC loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SsvnJTr1DEC7"
   },
   "outputs": [],
   "source": [
    "def rwmh(log_prob: Callable,\n",
    "         init_weights: Float[Array, \"num_features\"],\n",
    "         proposal_scale: float,\n",
    "         num_iters: int = 10000,\n",
    "         ) -> \\\n",
    "         Tuple[Float[Array, \"num_samples num_features\"], Float[Array, \"num_samples\"]]:\n",
    "    \"\"\" Run the random walk MH algorithm from the given starting point and for the\n",
    "    specified number of iterations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Array of weight samples and corresponding log joint probabilities.\n",
    "    \"\"\"\n",
    "    # Initialize the loop\n",
    "    curr_weights = init_weights\n",
    "    curr_log_prob = log_prob(curr_weights)\n",
    "    weight_samples = [curr_weights]\n",
    "    log_probs = [curr_log_prob]\n",
    "\n",
    "    for itr in progress_bar(range(num_iters)):\n",
    "        curr_weights, curr_log_prob = rwmh_step(log_prob,\n",
    "                                                curr_weights,\n",
    "                                                curr_log_prob,\n",
    "                                                proposal_scale)\n",
    "        weight_samples.append(curr_weights)\n",
    "        log_probs.append(curr_log_prob)\n",
    "\n",
    "    return torch.stack(weight_samples), torch.stack(log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_2yT5FhFWzf"
   },
   "source": [
    "### Let 'er rip!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "-NKpO5jZELOj",
    "outputId": "4f74ebc7-2cc4-4383-a544-b9a5f0dd5033"
   },
   "outputs": [],
   "source": [
    "# Make a log prob function that closes over the observations and hyperparams\n",
    "log_prob = lambda weights: log_joint(responses,\n",
    "                                     features,\n",
    "                                     weights,\n",
    "                                     mean_func,\n",
    "                                     prior_scale)\n",
    "\n",
    "# Run RWMH starting from \\beta = 0\n",
    "init_weights = torch.zeros(num_features)\n",
    "weight_samples, log_probs = rwmh(log_prob, init_weights, proposal_scale=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpYoaAgKFZmU"
   },
   "source": [
    "### Plot the results\n",
    "\n",
    "First look at the log joint probability as a function of MCMC iteration. It should go up and then stabilize. How does it compare to the log joint probability evaluated at the true weights, $\\beta^\\star$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "ITFIkHyREhww",
    "outputId": "ce0ba9fe-e70c-49be-ccd9-fa1a5b400630"
   },
   "outputs": [],
   "source": [
    "plt.plot(log_probs / num_data)\n",
    "plt.axhline(log_prob(true_weights) / num_data, color='r', ls=':')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"scaled log joint probability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1DqHOMqFuZ6"
   },
   "source": [
    "Now make a **trace plot** of the weights acros MCMC iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "urKy5fuiFyfH",
    "outputId": "14e8eab9-27ab-4ea9-ae7a-8083f3fd4d2a"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(num_features, 2, width_ratios=(5,1), sharey=True)\n",
    "for j in range(num_features):\n",
    "    # Plot the trace of the samples\n",
    "    axs[j, 0].plot(weight_samples[:, j])\n",
    "    axs[j, 0].axhline(true_weights[j], color='r', ls=':')\n",
    "    axs[j, 0].set_ylabel(r\"$\\beta_{}$\".format(j))\n",
    "    if j < num_features - 1: axs[j,0].set_xticklabels([])\n",
    "\n",
    "    # Plot a histogram of samples\n",
    "    axs[j, 1].hist(weight_samples[:, j], 20, orientation=\"horizontal\", density=True)\n",
    "    axs[j, 1].axhline(true_weights[j], color='r', ls=':')\n",
    "\n",
    "axs[0, 0].set_title(\"trace plot\")\n",
    "axs[0, 1].set_title(\"marginal\")\n",
    "axs[-1,0].set_xlabel(\"iteration\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWKeU0qCGR_5"
   },
   "source": [
    "Finally, let's approximate the posterior mean, $\\bar{\\beta}$, and plot the data and predicted probabilities under $\\bar{\\beta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "SUjUY5UrGsdw",
    "outputId": "1740a61c-28b9-4313-a98b-fb6d4c033e46"
   },
   "outputs": [],
   "source": [
    "mean_weights = weight_samples[100:].mean(axis=0)\n",
    "plot_sample(responses, features, mean_weights, mean_func)\n",
    "_ = plt.suptitle(\"Posterior Mean Weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "wVe2cb-kG3Yy",
    "outputId": "f63d10e0-457d-43bd-95c5-2bf084875072"
   },
   "outputs": [],
   "source": [
    "plot_sample(responses, features, true_weights, mean_func)\n",
    "_ = plt.suptitle(\"True Weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mWFVY0JYQt_"
   },
   "source": [
    "Finally, let's look at the MCMC estimate of the posterior _pairwise_ marginal $p(\\beta_1, \\beta_2 \\mid y, X)$ to see how correlated they are.\n",
    "\n",
    "**Question**: Before running the cell below, do you expect the weights to be correlated under the posterior? Explain your answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "WM_MnT4sZqlt",
    "outputId": "0a71bab2-ea0c-4bdd-81c8-8f900b675874"
   },
   "outputs": [],
   "source": [
    "plt.scatter(weight_samples[:, 1], weight_samples[:, 2], s=6, alpha=0.5, label=r\"$\\beta$ samples\")\n",
    "plt.plot(true_weights[1], true_weights[2], 'r*', ms=8, mew=2, label=r\"$\\beta^*$\")\n",
    "plt.xlabel(r\"$\\beta_1$\")\n",
    "plt.ylabel(r\"$\\beta_2$\")\n",
    "plt.legend()\n",
    "plt.gca().set_aspect(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vVxL77_JRWB"
   },
   "source": [
    "### Excercise\n",
    "\n",
    "Now go back and play with the hyperparameters.\n",
    "- What if you make the true weights larger &mdash; is the posterior more concentrated around the true weights?\n",
    "- What happens if you change the prior variance?\n",
    "- What happens if you change the proposal variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWNbFS63HJpq"
   },
   "source": [
    "## Robust Bayesian Linear Regression\n",
    "\n",
    "Now let's go on a little side quest and talk about robust linear regression. It will be a good excuse to introduce the concept of _augmentation_ and implement a Gibbs sampling algorithm. Then we'll come back to Bayesian GLMs and apply the same ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dff8g-pQJMd1"
   },
   "source": [
    "### Primer: Bayesian Linear Regression with Heteroskedastic Noise\n",
    "\n",
    "Suppose you have observations $y_i \\in \\mathbb{R}$ and features $x_i \\in \\mathbb{R}^p$. Unlike the ordinary linear regression setup, assume you have _heteroskedastic_ noise with known variance, $\\sigma_i^2$ for data points $i=1,\\ldots, n$.\n",
    "\n",
    "The joint probability is,\n",
    "\\begin{align*}\n",
    "p(y, \\beta \\mid X, \\sigma^2)\n",
    "&= p(\\beta) \\prod_{i=1}^n p(y_i \\mid \\beta, x_i, \\sigma_i^2) \\\\\n",
    "&= \\mathrm{N}(\\beta \\mid 0, \\gamma^{-1} I) \\prod_{i=1}^n \\mathrm{N}(y_i \\mid \\beta^\\top x_i, \\sigma_i^2)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eIzA4CPUKAcl"
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Derive the posterior distribution $p(\\beta \\mid y, X, \\sigma^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRJ5uiskKkxu"
   },
   "source": [
    "### Robust Regression with Students' T Noise\n",
    "\n",
    "The model above makes the strong and often unreasonable assumption that we _know the noise variance_ for each data point. A more reasonable assumption is to consider a model with heavy-tailed noise, like the following,\n",
    "\\begin{align*}\n",
    "p(y, \\beta \\mid X)\n",
    "&= \\mathrm{N}(\\beta \\mid 0, \\gamma^{-1} I) \\prod_{i=1}^n \\mathrm{St}(y_i \\mid \\beta^\\top x_i, \\sigma_0^2, \\nu)\n",
    "\\end{align*}\n",
    "where $\\mathrm{St}(\\mu, \\sigma_0^2, \\nu)$ denotes the **Students' t distribution** with mean $\\mu$, scale $\\sigma_0$, and $\\nu$ degrees of freedom. Its density is,\n",
    "\\begin{align}\n",
    "    \\mathrm{St}(y; \\mu, \\sigma_0^2, \\nu)\n",
    "    &= \\frac{\\Gamma(\\tfrac{\\nu + 1}{2})}{\\Gamma(\\tfrac{\\nu}{2})} \\frac{1}{\\sqrt{\\pi \\nu \\sigma_0^2}} \\left[1 + \\frac{\\Delta^2}{\\nu} \\right]^{-\\tfrac{\\nu + 1}{2}}\n",
    "\\end{align}\n",
    "where $\\Delta^2 = \\left(\\tfrac{y - \\mu}{\\sigma_0} \\right)^2$ is the squared Mahalanobis distance.\n",
    "Its mean is $\\mu$ and its variance is $\\frac{\\nu}{\\nu + 2} \\sigma_0^2$.\n",
    "\n",
    "Unfortunately, the Student's t distribution is not conjugate with the Gaussian prior (convince yourself).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RPYQxeOQ5sH"
   },
   "source": [
    "### Student's t as a scale-mixture of Gaussians\n",
    "However, here's a **nifty trick**! The Student's t density can be written as a scale-mixture of Gaussians,\n",
    "\\begin{align}\n",
    "\\mathrm{St}\\left(y; \\mu, \\sigma_0^2, \\nu \\right)\n",
    "&= \\int \\mathrm{IGa}(\\sigma \\mid \\tfrac{\\nu}{2}, \\tfrac{\\nu \\sigma_0^2}{2}) \\, \\mathrm{N}(y \\mid \\mu, \\sigma^2) \\, \\mathrm{d} \\sigma^2\n",
    "\\end{align}\n",
    "where $\\mathrm{IGa}$ denotes the **inverse gamma distribution**, which has density\n",
    "\\begin{align*}\n",
    "\\mathrm{IGa}(\\sigma^2 \\mid a, b)\n",
    "&= \\frac{b^a}{\\Gamma(a)} (\\sigma^2)^{-a - 1} e^{-\\frac{b}{\\sigma^2}}\n",
    "\\end{align*}\n",
    "\n",
    "When $a = \\nu/2$ and $b = \\nu \\sigma_0^2 /2$, it has mean $\\mathbb{E}[\\sigma^2] = \\frac{\\nu}{\\nu - 2} \\sigma_0^2$ (for $\\nu > 2$) and the variance shrinks as $\\nu$ increases.\n",
    "\n",
    "Notes:\n",
    "- The inverse gamma is equivalent to a scaled inverse chi-squared distribution with degrees of freedom $\\nu$ and scale $\\sigma_0^2$.\n",
    "- If $\\sigma \\sim \\mathrm{IGa}(a, b)$ then $\\sigma^{-1} \\sim \\mathrm{Ga}(a, b)$, so we can also think of the Student's t distribution as a continuous mixture of Gaussians with gamma distributed _precisions_.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jg6IUTqYN5pn"
   },
   "source": [
    "### Augmentation Tricks\n",
    "\n",
    "We can use the integral representation of the Student's t distribution to write our joint distribution as a marginal of an augmented model. To be precise, we can write the joint distribution above as,\n",
    "\\begin{align*}\n",
    "p(y, \\beta \\mid X)\n",
    "&= \\mathrm{N}(\\beta \\mid 0, \\gamma^{-1} I) \\prod_{i=1}^n \\mathrm{St}(y_i \\mid \\beta^\\top x_i, \\sigma_0^2, \\nu) \\\\\n",
    "&= \\mathrm{N}(\\beta \\mid 0, \\gamma^{-1} I) \\prod_{i=1}^n \\int \\mathrm{IGa}(\\sigma_i \\mid \\tfrac{\\nu}{2}, \\tfrac{\\nu \\sigma_0^2}{2}) \\, \\mathrm{N}(y_i \\mid \\beta^\\top x_i, \\sigma_i^2) \\, \\mathrm{d} \\sigma_i^2 \\\\\n",
    "&= \\int p(y, \\beta, \\sigma \\mid X) \\, \\mathrm{d}\\sigma_1^2 \\cdots \\mathrm{d} \\sigma_n^2\n",
    "\\end{align*}\n",
    "\n",
    "The nice thing about Monte Carlo is that if we can draw samples from the posterior distribution of the augmented model, $p(\\beta, \\sigma \\mid y, X)$, then we can simply discard our samples of $\\sigma$ when calculating posterior expectations that are functions of $\\beta$. That is,\n",
    "\\begin{align*}\n",
    "\\mathbb{E}_{p(\\beta \\mid y, X)} [g(\\beta)]\n",
    "&= \\mathbb{E}_{p(\\beta, \\sigma^2 \\mid y, X)} [g(\\beta)] \\\\\n",
    "&\\approx \\frac{1}{M} g(\\beta^{(m)}) & \\text{where} \\; \\beta^{(m)}, \\sigma^{(m)} &\\sim p(\\beta, \\sigma^2 \\mid y, X)\n",
    "\\end{align*}\n",
    "\n",
    "It may sound strictly harder to draw samples from the posterior of $\\beta$ and $\\sigma^2$ than from the posterior of $\\beta$ alone, but that's not always the case! For example, in this augmented model, note that the conditional distributions have nice closed forms. In particular,\n",
    "\\begin{align*}\n",
    "p(\\beta \\mid y, X, \\sigma^2)\n",
    "&\\propto \\mathrm{N}(\\beta \\mid 0, \\gamma^{-1} I) \\prod_{i=1}^n \\mathrm{N}(y_i \\mid \\beta^\\top x_i, \\sigma_i^2).\n",
    "\\end{align*}\n",
    "This is exactly the Bayesian linear regression model with known, heteroskedastic noise that we solved above!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJwK4hzSSxLP"
   },
   "source": [
    "#### Exercise\n",
    "Derive the conditional distribution $p(\\sigma_i^2 \\mid y_i, x_i, \\beta)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2M7v2Y4az0m"
   },
   "source": [
    "### Generate Synthetic Data\n",
    "\n",
    "Now let's generate some synthetic data from the robust linear regression model. Here, we'll use just an intercept and a slope, so $\\beta \\in \\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwKQDSx1az0m"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(305 + ord('b'))\n",
    "\n",
    "# Set constants\n",
    "num_features = 2                # first \"feature\" is all ones\n",
    "num_data = 20                  # number of data points to sample\n",
    "noise_scale = 1.0               # scale of the Student's t noise\n",
    "noise_dof = 2.0                 # degrees of freedom of the Student's t noise\n",
    "prior_scale = 3.                # std of Gaussian prior \\gamma^{-1/2}\n",
    "\n",
    "# Fix true weights. Sample features, and responses.\n",
    "true_weights = torch.tensor([0., 1.])\n",
    "\n",
    "features = torch.column_stack([\n",
    "    torch.ones(num_data),\n",
    "    Normal(0, 1).sample((num_data, num_features-1))\n",
    "])\n",
    "\n",
    "# Sample from a model with a mixture of Gaussians noise distribution\n",
    "responses = StudentT(noise_dof, features @ true_weights, noise_scale).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "Jl8yrKekcqrV",
    "outputId": "7e93034a-9743-4b6d-9548-03d84c1bbc2f"
   },
   "outputs": [],
   "source": [
    "# Plot the data and overlay the OLS estimate of the weights\n",
    "def plot_robust_reg_data(responses,\n",
    "                         features,\n",
    "                         true_weights,\n",
    "                         weights_labels=(),\n",
    "                         lim=(-3, 3)):\n",
    "    plt.plot(features[:, 1], responses, 'o')\n",
    "    xs = torch.linspace(*lim, 100)\n",
    "    plt.plot(xs, true_weights[0] + true_weights[1] * xs, '-r', label=\"true\")\n",
    "    for weights, label in weights_labels:\n",
    "        plt.plot(xs, weights[0] + weights[1] * xs, label=label)\n",
    "    plt.xlim(lim)\n",
    "    plt.xlabel(r\"$x$\")\n",
    "    plt.ylabel(r\"$y$\")\n",
    "    plt.legend()\n",
    "\n",
    "ols_weights = torch.linalg.solve(features.T @ features, features.T @ responses)\n",
    "plot_robust_reg_data(responses, features, true_weights, [(ols_weights, \"OLS\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_WeJcqwWJ_a"
   },
   "source": [
    "### Implement a Gibbs sampler\n",
    "\n",
    "Now implement a Gibbs sampling algorithm to approximate the posterior distribution of the weights in the robust regression model. Specifically, write functions to sample the weights given noise variances and the noise variances given the weights. The Gibbs sampling algorithm will alternate between these two steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rFeGiLChIWB",
    "outputId": "f2f6203f-6d3a-4701-a842-0b182723d6d5"
   },
   "outputs": [],
   "source": [
    "def log_joint(responses: Float[Array, \"num_data\"],\n",
    "              features: Float[Array, \"num_data num_features\"],\n",
    "              weights: Float[Array, \"num_features\"],\n",
    "              prior_scale: float,\n",
    "              noise_dof: float,\n",
    "              noise_scale: float) -> float:\n",
    "    \"\"\" Compute the log joint probability of the robust regression model \"\"\"\n",
    "\n",
    "    lp = Normal(0, prior_scale).log_prob(weights).sum()\n",
    "    lp += StudentT(noise_dof, features @ weights, noise_scale).log_prob(responses).sum()\n",
    "    return lp\n",
    "\n",
    "# Test that it runs\n",
    "log_joint(responses, features, true_weights, prior_scale, noise_dof, noise_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18hB5bWgdb2Q",
    "outputId": "cdf5855f-a488-4a80-ab9b-796864a69fef"
   },
   "outputs": [],
   "source": [
    "def gibbs_step_weights(responses: Float[Array, \"num_data\"],\n",
    "                       features: Float[Array, \"num_data num_features\"],\n",
    "                       noise_variances: Float[Array, \"num_data\"],\n",
    "                       prior_scale: float) -> \\\n",
    "                       Float[Array, \"num_features\"]:\n",
    "    \"\"\" Perform a Gibbs step to sample the weights from their conditional.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Next sample of the weights\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    new_weights = ...\n",
    "    return new_weights\n",
    "\n",
    "# Test that it runs\n",
    "dummy_noise_vars = torch.ones(num_data)\n",
    "gibbs_step_weights(responses, features, dummy_noise_vars, prior_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TbrFN74e_A7",
    "outputId": "fa3102e9-5f82-43f0-d20b-82882bdb0faf"
   },
   "outputs": [],
   "source": [
    "def gibbs_step_noise_vars(responses: Float[Array, \"num_data\"],\n",
    "                          features: Float[Array, \"num_data num_features\"],\n",
    "                          weights: Float[Array, \"num_features\"],\n",
    "                          noise_dof: float,\n",
    "                          noise_scale: float) -> \\\n",
    "                          Float[Array, \"num_dat\"]:\n",
    "    \"\"\" Perform a Gibbs step to sample the auxiliary noise variances from their conditionals.\n",
    "\n",
    "    Note that the noise variances are conditionally independent and hence can be sampled\n",
    "    in parallel.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Next sample of the noise variances.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    new_noise_vars = ...\n",
    "    return new_noise_vars\n",
    "\n",
    "# Test that it runs\n",
    "gibbs_step_noise_vars(responses, features, true_weights, noise_dof, noise_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ql9JL66ygr_G"
   },
   "outputs": [],
   "source": [
    "def gibbs(responses: Float[Array, \"num_data\"],\n",
    "          features: Float[Array, \"num_data num_features\"],\n",
    "          init_weights: Float[Array, \"num_features\"],\n",
    "          prior_scale: float,\n",
    "          noise_dof: float,\n",
    "          noise_scale: float,\n",
    "          num_iters: int = 10000,\n",
    "          ) -> \\\n",
    "         Tuple[Float[Array, \"num_samples num_features\"], Float[Array, \"num_samples\"]]:\n",
    "    \"\"\" Run the random walk MH algorithm from the given starting point and for the\n",
    "    specified number of iterations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Array of weight samples and corresponding log joint probabilities.\n",
    "    \"\"\"\n",
    "    # Helper function to compute log prob as a function of the weights\n",
    "    lp = lambda weights: log_joint(responses,\n",
    "                                   features,\n",
    "                                   weights,\n",
    "                                   prior_scale,\n",
    "                                   noise_dof,\n",
    "                                   noise_scale)\n",
    "\n",
    "    # Initialize the loop\n",
    "    weights = init_weights\n",
    "    weight_samples = [weights]\n",
    "    log_probs = [lp(weights)]\n",
    "\n",
    "    for itr in progress_bar(range(num_iters)):\n",
    "        noise_vars = gibbs_step_noise_vars(responses, features, weights, noise_dof, noise_scale)\n",
    "        weights = gibbs_step_weights(responses, features, noise_vars, prior_scale)\n",
    "\n",
    "        weight_samples.append(weights)\n",
    "        log_probs.append(lp(weights))\n",
    "\n",
    "    return torch.stack(weight_samples), torch.stack(log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0z0vGBFZiYmF"
   },
   "source": [
    "### Let 'er rip!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "c9ul27lciYmG",
    "outputId": "7c4c7c90-1079-4203-ddfb-de0f065c5929"
   },
   "outputs": [],
   "source": [
    "# Run Gibbs starting from \\beta = 0\n",
    "init_weights = torch.zeros(num_features)\n",
    "weight_samples, log_probs = gibbs(responses, features, init_weights, prior_scale, noise_dof, noise_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_e0moU8ZiVxP"
   },
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "cp3DgE3Hiz37",
    "outputId": "d4a5a605-c95a-4790-ca4d-3262620340b6"
   },
   "outputs": [],
   "source": [
    "plt.plot(log_probs / num_data)\n",
    "plt.axhline(log_joint(responses, features, true_weights, prior_scale, noise_dof, noise_scale) / num_data, color='r', ls=':')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"scaled log joint probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "lw_5p4IajE9-",
    "outputId": "31fcf268-a722-4b17-9692-dd29e0527d00"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(num_features, 2, width_ratios=(5,1), sharey=True)\n",
    "for j in range(num_features):\n",
    "    # Plot the trace of the samples\n",
    "    axs[j, 0].plot(weight_samples[:, j])\n",
    "    axs[j, 0].axhline(true_weights[j], color='r', ls=':')\n",
    "    axs[j, 0].set_ylabel(r\"$\\beta_{}$\".format(j))\n",
    "    if j < num_features - 1: axs[j,0].set_xticklabels([])\n",
    "\n",
    "    # Plot a histogram of samples\n",
    "    axs[j, 1].hist(weight_samples[:, j], 20, orientation=\"horizontal\", density=True)\n",
    "    axs[j, 1].axhline(true_weights[j], color='r', ls=':')\n",
    "\n",
    "axs[0, 0].set_title(\"trace plot\")\n",
    "axs[0, 1].set_title(\"marginal\")\n",
    "axs[-1,0].set_xlabel(\"iteration\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vx2Dmb5GjM17"
   },
   "source": [
    "Plot the posterior mean of the weights. Is it any closer to the true weights than the OLS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "wvph5IzHjQhe",
    "outputId": "c926066e-6e63-4d2b-e5e7-25437c1ab4b5"
   },
   "outputs": [],
   "source": [
    "mean_weights = weight_samples.mean(axis=0)\n",
    "plot_robust_reg_data(responses, features, true_weights,\n",
    "                     [(ols_weights, \"OLS\"),\n",
    "                      (mean_weights, \"Posterior mean\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qWBEP6gkUnt"
   },
   "source": [
    "## Bayesian Probit Regression\n",
    "\n",
    "There are cool augmentation tricks for Bayesian GLMs too! For example, consider a Bernoulli GLM with the _probit_ link function,\n",
    "\\begin{align*}\n",
    "f(a) &= \\int_{-\\infty}^a \\mathrm{N}(z ; 0, 1) \\, \\mathrm{d} z \\triangleq \\Phi(a),\n",
    "\\end{align*}\n",
    "i.e., the normal CDF. Like the logistic function, the normal CDF is a monotonically increasing function that defines a bijective mapping from $\\mathbb{R} \\mapsto (0,1)$. With this mean function, the Bernoulli GLM likelihood is,\n",
    "\\begin{align*}\n",
    "p(y_i \\mid x_i, \\beta)\n",
    "&= \\mathrm{Bern}(y_i \\mid \\Phi(\\beta^\\top x_i)) \\\\\n",
    "&= \\Phi(\\beta^\\top x_i)^{y_i} (1 - \\Phi(\\beta^\\top x_i))^{1 - y_i}.\n",
    "\\end{align*}\n",
    "{cite:t}`albert1993bayesian` noted that we can rewrite this likelihood using the integral representation of the mean function, together with a few handy transformations. Namely,\n",
    "\\begin{align*}\n",
    "\\Phi(a) = \\int_{-\\infty}^a \\mathrm{N}(z ; 0, 1) \\, \\mathrm{d} z\n",
    "&= \\int_{0}^\\infty \\mathrm{N}(z; a, 1) \\, \\mathrm{d} z,\n",
    "\\end{align*}\n",
    "\\begin{align*}\n",
    "1 - \\Phi(a) &= \\int_{-\\infty}^0 \\mathrm{N}(z; a, 1) \\, \\mathrm{d} z.\n",
    "\\end{align*}\n",
    "Substituting these expressions into the likelihood above,\n",
    "\\begin{align*}\n",
    "p(y_i \\mid x_i, \\beta)\n",
    "&= \\mathrm{Bern}(y_i \\mid \\Phi(\\beta^\\top x_i)) \\\\\n",
    "&= \\left[\\int_{0}^\\infty \\mathrm{N}(z_i; \\beta^\\top x_i, 1) \\, \\mathrm{d} z_i \\right]^{y_i} \\left[\\int_{-\\infty}^0 \\mathrm{N}(z_i; \\beta^\\top x_i, 1) \\, \\mathrm{d} z_i \\right]^{1 - y_i} \\\\\n",
    "&= \\int_{-\\infty}^\\infty p(y_i \\mid z_i) \\, \\mathrm{N}(z_i \\mid \\beta^\\top x_i, 1) \\, \\mathrm{d} z_i\n",
    "\\end{align*}\n",
    "where\n",
    "\\begin{align}\n",
    "    p(y_i \\mid z_i) &=\n",
    "    \\begin{cases}\n",
    "    \\delta_1(y_i) & \\text{if } z_i > 0\\\\\n",
    "    \\delta_0(y_i) & \\text{if } z_i \\leq 0\n",
    "    \\end{cases}\n",
    "\\end{align}\n",
    "In other words, we can view the Bernoulli likelihood with probit link as the marginal of a joint distribution, $p(y_i, z_i \\mid x_i, \\beta)$. In this particular joint distribution, $y_i$ is deterministic given $z_i$.\n",
    "\n",
    "Another way to think about this augmented model is that we only observe the sign  of a latent variable $z_i$ (where $y_i=0$ if $z_i$ is negative, and $y_i=1$ if it is positive). The latent variable is itself a noisy perturbation of the linear model's prediction, $\\beta^\\top x_i$. The challenge is, given these observations of the sign, to estimate the underlying weights $\\beta$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0ObfTa1xgvy"
   },
   "source": [
    "\n",
    "### Exercise\n",
    "\n",
    "1. Show that the conditional distribution of the latent variable $z_i$ in the augmented model is a **truncated normal distribution**.\n",
    "\n",
    "2. Show that the conditional distribution of the weights given the latent variables $z_i$ is multivariate normal.\n",
    "\n",
    "3. Implement a Gibbs sampling algorithm to draw samples from the joint distribution $p(z, \\beta \\mid y, X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wmp0ErPOxom9"
   },
   "source": [
    "## Augmentation Schemes for Bayesian Logistic Regression\n",
    "\n",
    "We can apply the same logic to the logistic regression case by viewing the logistic function as the CDF of a distribution on the real line. It turns out the corresponding distribution is the aptly named [**logistic distribution**](https://en.wikipedia.org/wiki/Logistic_distribution) with pdf,\n",
    "\\begin{align*}\n",
    "\\mathrm{Logistic}(u; 0, 1) = \\frac{\\mathrm{d}}{\\mathrm{d} u} \\sigma(u) = \\sigma(u) ( 1 - \\sigma(u)) = \\frac{e^u}{(1+e^u)^2}.\n",
    "\\end{align*}\n",
    "Then, we can interpret the Bernoulli likelihood with logistic mean function as a marginal of the auxiliary model,\n",
    "\\begin{align*}\n",
    "u_i &\\sim \\mathrm{Logistic}(0, 1) \\\\\n",
    "z_i &= x_i^\\top \\beta + u_i \\\\\n",
    "y_i &= \\mathbb{I}[z_i > 0].\n",
    "\\end{align*}\n",
    "Or, as with the probit model above,\n",
    "\\begin{align*}\n",
    "z_i &\\sim \\mathrm{Logistic}(x_i^\\top \\beta, 1) \\\\\n",
    "y_i &= \\mathbb{I}[z_i > 0].\n",
    "\\end{align*}\n",
    "The logistic distribution is heavier tailed than a Gaussian. In fact, its is closer to a Student's t distribution with 9 degrees of freedom and slightly inflated scale, as shown below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "ZxJx_fCbz6x0",
    "outputId": "e9cc4a81-c36a-45ed-9ec2-1c79224ea19e"
   },
   "outputs": [],
   "source": [
    "zs = torch.linspace(-8, 8, 1000)\n",
    "plt.plot(zs, torch.sigmoid(zs) * torch.sigmoid(-zs), lw=3, label=\"logistic\")\n",
    "plt.plot(zs, torch.exp(StudentT(9, 0, 1.55).log_prob(zs)), '--', label=\"St(0, 1.55, 9)\", )\n",
    "plt.plot(zs, torch.exp(Normal(0, 1).log_prob(zs)), label=\"normal\")\n",
    "plt.legend()\n",
    "plt.xlabel(r\"$z$\")\n",
    "plt.ylabel(r\"$p(z)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PF3ntCeC2pjn"
   },
   "source": [
    "This motivates a simple approximation of $z_i \\sim \\mathrm{St}(9, x_i^\\top \\beta, 1.55)$. Using this approximation, you can perform Gibbs sampling on the conjugate model, alternating between updating $\\beta$ from its Gaussian conditional, and updating $z_i$ from its truncated Student's t conditional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPn-gz822qNZ"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This lecture looks works through some actual implementations of MCMC algorithms and develops some useful tricks for Gibbs sampling via augmentation. There are some even better approaches out there for Gibbs sampling in logistic models, and we'll explore them in the homework assignment!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
